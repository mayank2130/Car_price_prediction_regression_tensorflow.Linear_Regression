# Import 

import tensorflow as tf
import pandas as pd
import seaborn as sns
from tensorflow.keras.layers import Normalization, Dense, InputLayer
import matplotlib.pyplot as plt
import numpy as np

# Data Preparation

data = pd.read_csv("train.csv", ",")
data.head()

# Check the data shape
data.shape

# We can visualize our dataset by useing seaborn pairplot
sns.pairplot(data[["years",	"km", "rating",	"condition",	"economy",	"top speed",	"hp",	"torque",	"current price"]], diag_kind='kde')

# Convert data into tensors
tensor_data = tf.constant(data)
tensor_data = tf.cast(tensor_data, tf.float32)

# Shuffle the dataset to remove any bias
tensor_data = tf.random.shuffle(tensor_data)
tensor_data[5]

# Define features(X) and Labels(y)
X = tensor_data[:, 3:-1]
X.shape

y = tensor_data[:, -1]
# Add an extra dimension so it matches that of the input
y = tf.expand_dims(y, axis=-1)
y.shape

TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
TEST_RATIO = 0.1
DATASET_SIZE = len(X)

X_train = X[:int(DATASET_SIZE*TRAIN_RATIO)]
y_train = y[:int(DATASET_SIZE*TRAIN_RATIO)]
print(X_train.shape)
print(y_train.shape)

train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)

X_val = X[int(DATASET_SIZE*TRAIN_RATIO):int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO))]
y_val = y[int(DATASET_SIZE*TRAIN_RATIO):int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO))]
print(X_val.shape)
print(y_val.shape)

val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))
val_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)

X_test = X[int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO)):]
y_test = y[int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO)):]
print(X_test.shape)
print(y_test.shape)

test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))
test_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)

# Now normalize our input data
normalizer = Normalization()
normalizer.adapt(X_train)
normalizer(X)[:5]


# Build a Model
model = tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(8,)),
    normalizer,
    tf.keras.layers.Dense(100, activation="relu"),
    tf.keras.layers.Dense(100, activation="relu"),
    tf.keras.layers.Dense(100, activation="relu"),
    tf.keras.layers.Dense(100, activation="relu"),
    tf.keras.layers.Dense(1)
])
model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
              metrics=["mae"])         

history = model.fit(train_dataset, validation_data=val_dataset, epochs = 100, verbose = 1)


pd.DataFrame(history.history).plot()
plt.ylabel("loss")
plt.xlabel("epochs")

# Evaluate our model
    model.evaluate(X_test, y_test)

b = np.broadcast_arrays(X_test, y_test[:, None])

# Visualize Our Model predictions
y_true = list(y_test[:,0].numpy())
y_pred = list(model.predict(X_test)[:,0])
print(y_pred)

ind = np.arange(100)
plt.figure(figsize=(40,12))

width = 0.4

plt.bar(ind, y_pred, width, label='Predicted Car Price')
plt.bar(ind + width, y_true, width, label='Actual Car Price')

plt.xlabel('Actual vs Predicted Prices')
plt.ylabel('Car Price Prices')

plt.show()
